{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read drivers' list... ...\n",
      "Read train images... ... \n",
      "Load folder c0... ...\n",
      "Load folder c1... ...\n",
      "Load folder c2... ...\n",
      "Load folder c3... ...\n",
      "Load folder c4... ...\n",
      "Load folder c5... ...\n",
      "Load folder c6... ...\n",
      "Load folder c7... ...\n",
      "Load folder c8... ...\n",
      "Load folder c9... ...\n",
      "Read train data time: 128.76 seconds\n",
      "Unique drivers: 26\n",
      "['p002', 'p012', 'p014', 'p015', 'p016', 'p021', 'p022', 'p024', 'p026', 'p035', 'p039', 'p041', 'p042', 'p045', 'p047', 'p049', 'p050', 'p051', 'p052', 'p056', 'p061', 'p064', 'p066', 'p072', 'p075', 'p081']\n",
      "Directory doesnt exists\n",
      "Train shape: (22424, 1, 224, 224)\n",
      "22424 train samples\n",
      "Read test images... ...\n",
      "Read 7972 images from 79726\n",
      "Read 15944 images from 79726\n",
      "Read 23916 images from 79726\n",
      "Read 31888 images from 79726\n",
      "Read 39860 images from 79726\n",
      "Read 47832 images from 79726\n",
      "Read 55804 images from 79726\n",
      "Read 63776 images from 79726\n",
      "Read 71748 images from 79726\n",
      "Read 79720 images from 79726\n",
      "Read test data time: 427.05 seconds\n",
      "Directory doesnt exists\n",
      "Test shape: (79726, 1, 224, 224)\n",
      "79726 test samples\n",
      "Start Single Run\n",
      "Split train:  21601 21601\n",
      "Split valid:  823 823\n",
      "Train drivers: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:420: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (7, 7), name=\"conv1\", strides=(2, 2), use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:364: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (1, 1), name=\"res2a_branch2a\", strides=(1, 1), use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:371: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), name=\"res2a_branch2b\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:376: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res2a_branch2c\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:381: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res2a_branch1\", strides=(1, 1), use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:385: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "e:\\Anaconda3\\lib\\site-packages\\keras\\legacy\\layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:326: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (1, 1), name=\"res2b_branch2a\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:333: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), name=\"res2b_branch2b\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:338: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res2b_branch2c\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:342: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:326: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (1, 1), name=\"res2c_branch2a\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:333: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), name=\"res2c_branch2b\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:338: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res2c_branch2c\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:364: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), name=\"res3a_branch2a\", strides=(2, 2), use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:371: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), name=\"res3a_branch2b\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:376: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (1, 1), name=\"res3a_branch2c\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:381: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (1, 1), name=\"res3a_branch1\", strides=(2, 2), use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:326: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), name=\"res3b1_branch2a\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:333: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), name=\"res3b1_branch2b\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:338: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (1, 1), name=\"res3b1_branch2c\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:326: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), name=\"res3b2_branch2a\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:333: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), name=\"res3b2_branch2b\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:338: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (1, 1), name=\"res3b2_branch2c\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:326: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), name=\"res3b3_branch2a\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:333: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), name=\"res3b3_branch2b\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:338: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (1, 1), name=\"res3b3_branch2c\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:364: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res4a_branch2a\", strides=(2, 2), use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:371: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"res4a_branch2b\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:376: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), name=\"res4a_branch2c\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:381: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), name=\"res4a_branch1\", strides=(2, 2), use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:326: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res4b1_branch2a\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:333: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"res4b1_branch2b\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:338: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), name=\"res4b1_branch2c\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:326: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res4b2_branch2a\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:333: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"res4b2_branch2b\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:338: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), name=\"res4b2_branch2c\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:326: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res4b3_branch2a\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:333: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"res4b3_branch2b\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:338: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), name=\"res4b3_branch2c\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:326: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res4b4_branch2a\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:333: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"res4b4_branch2b\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:338: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), name=\"res4b4_branch2c\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:326: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res4b5_branch2a\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:333: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"res4b5_branch2b\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:338: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), name=\"res4b5_branch2c\", use_bias=False)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:326: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res4b6_branch2a\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:333: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"res4b6_branch2b\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:338: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), name=\"res4b6_branch2c\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:326: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res4b7_branch2a\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:333: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"res4b7_branch2b\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:338: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), name=\"res4b7_branch2c\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:326: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res4b8_branch2a\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:333: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"res4b8_branch2b\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:338: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), name=\"res4b8_branch2c\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:326: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res4b9_branch2a\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:333: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"res4b9_branch2b\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:338: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), name=\"res4b9_branch2c\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:326: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res4b10_branch2a\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:333: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"res4b10_branch2b\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:338: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), name=\"res4b10_branch2c\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:326: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res4b11_branch2a\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:333: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"res4b11_branch2b\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:338: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), name=\"res4b11_branch2c\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:326: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res4b12_branch2a\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:333: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"res4b12_branch2b\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:338: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), name=\"res4b12_branch2c\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:326: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res4b13_branch2a\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:333: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"res4b13_branch2b\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:338: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), name=\"res4b13_branch2c\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:326: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res4b14_branch2a\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:333: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"res4b14_branch2b\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:338: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), name=\"res4b14_branch2c\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:326: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res4b15_branch2a\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:333: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"res4b15_branch2b\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:338: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), name=\"res4b15_branch2c\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:326: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res4b16_branch2a\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:333: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"res4b16_branch2b\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:338: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), name=\"res4b16_branch2c\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:326: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res4b17_branch2a\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:333: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"res4b17_branch2b\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:338: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), name=\"res4b17_branch2c\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:326: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res4b18_branch2a\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:333: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"res4b18_branch2b\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:338: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), name=\"res4b18_branch2c\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:326: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res4b19_branch2a\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:333: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"res4b19_branch2b\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:338: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), name=\"res4b19_branch2c\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:326: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res4b20_branch2a\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:333: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"res4b20_branch2b\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:338: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), name=\"res4b20_branch2c\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:326: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res4b21_branch2a\", use_bias=False)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:333: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"res4b21_branch2b\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:338: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), name=\"res4b21_branch2c\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:326: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), name=\"res4b22_branch2a\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:333: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), name=\"res4b22_branch2b\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:338: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1), name=\"res4b22_branch2c\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:364: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (1, 1), name=\"res5a_branch2a\", strides=(2, 2), use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:371: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), name=\"res5a_branch2b\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:376: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(2048, (1, 1), name=\"res5a_branch2c\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:381: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(2048, (1, 1), name=\"res5a_branch1\", strides=(2, 2), use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:326: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (1, 1), name=\"res5b_branch2a\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:333: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), name=\"res5b_branch2b\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:338: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(2048, (1, 1), name=\"res5b_branch2c\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:326: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (1, 1), name=\"res5c_branch2a\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:333: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), name=\"res5c_branch2b\", use_bias=False)`\n",
      "e:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:338: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(2048, (1, 1), name=\"res5c_branch2c\", use_bias=False)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ['p002', 'p012', 'p014', 'p015', 'p016', 'p021', 'p022', 'p024', 'p026', 'p035', 'p039', 'p041', 'p042', 'p045', 'p047', 'p049', 'p050', 'p051', 'p052', 'p056', 'p061', 'p064', 'p066', 'p072', 'p075']\n",
      "Test drivers:  ['p081']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimension 0 in both shapes must be equal, but are 7 and 64 for 'Assign' (op: 'Assign') with input shapes: [7,7,1,64], [64,3,7,7].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[1;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[0;32m    653\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 654\u001b[1;33m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[0;32m    655\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[1;34m()\u001b[0m\n\u001b[0;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 466\u001b[1;33m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[0;32m    467\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Dimension 0 in both shapes must be equal, but are 7 and 64 for 'Assign' (op: 'Assign') with input shapes: [7,7,1,64], [64,3,7,7].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-16873867d48b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    557\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 559\u001b[1;33m \u001b[0mrun_single\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-1-16873867d48b>\u001b[0m in \u001b[0;36mrun_single\u001b[1;34m()\u001b[0m\n\u001b[0;32m    531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m \u001b[1;31m#    model = create_model_v1(img_rows, img_cols, color_type_global)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 533\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mresnet101_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_rows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_cols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor_type_global\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    534\u001b[0m     model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n\u001b[0;32m    535\u001b[0m                shuffle=True, verbose=1, validation_data=(X_valid, Y_valid))\n",
      "\u001b[1;32m<ipython-input-1-16873867d48b>\u001b[0m in \u001b[0;36mresnet101_model\u001b[1;34m(img_rows, img_cols, color_type, num_classes)\u001b[0m\n\u001b[0;32m    453\u001b[0m       \u001b[0mweights_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'imagenet_models/resnet101_weights_tf.h5'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 455\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    456\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m     \u001b[1;31m# Truncate and replace softmax layer for transfer learning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name)\u001b[0m\n\u001b[0;32m   2615\u001b[0m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model_weights'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2616\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mby_name\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2617\u001b[1;33m             \u001b[0mload_weights_from_hdf5_group_by_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2618\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2619\u001b[0m             \u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group_by_name\u001b[1;34m(f, layers)\u001b[0m\n\u001b[0;32m   3156\u001b[0m                 weight_value_tuples.append((symbolic_weights[i],\n\u001b[0;32m   3157\u001b[0m                                             weight_values[i]))\n\u001b[1;32m-> 3158\u001b[1;33m     \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[1;34m(tuples)\u001b[0m\n\u001b[0;32m   2186\u001b[0m                 assign_placeholder = tf.placeholder(tf_dtype,\n\u001b[0;32m   2187\u001b[0m                                                     shape=value.shape)\n\u001b[1;32m-> 2188\u001b[1;33m                 \u001b[0massign_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2189\u001b[0m                 \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_assign_placeholder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0massign_placeholder\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2190\u001b[0m                 \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_assign_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0massign_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\u001b[0m in \u001b[0;36massign\u001b[1;34m(self, value, use_locking)\u001b[0m\n\u001b[0;32m    525\u001b[0m       \u001b[0mthe\u001b[0m \u001b[0massignment\u001b[0m \u001b[0mhas\u001b[0m \u001b[0mcompleted\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    526\u001b[0m     \"\"\"\n\u001b[1;32m--> 527\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mstate_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_locking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0massign_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\state_ops.py\u001b[0m in \u001b[0;36massign\u001b[1;34m(ref, value, validate_shape, use_locking, name)\u001b[0m\n\u001b[0;32m    272\u001b[0m     return gen_state_ops.assign(\n\u001b[0;32m    273\u001b[0m         \u001b[0mref\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_locking\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 274\u001b[1;33m         validate_shape=validate_shape)\n\u001b[0m\u001b[0;32m    275\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_state_ops.py\u001b[0m in \u001b[0;36massign\u001b[1;34m(ref, value, validate_shape, use_locking, name)\u001b[0m\n\u001b[0;32m     41\u001b[0m   result = _op_def_lib.apply_op(\"Assign\", ref=ref, value=value,\n\u001b[0;32m     42\u001b[0m                                 \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m                                 use_locking=use_locking, name=name)\n\u001b[0m\u001b[0;32m     44\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    765\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    766\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 767\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    768\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[0;32m   2630\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[0;32m   2631\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2632\u001b[1;33m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2633\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2634\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   1909\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1910\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1911\u001b[1;33m   \u001b[0mshapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1912\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1913\u001b[0m     raise RuntimeError(\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   1859\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1860\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1861\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1862\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1863\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[1;34m(op, require_shape_fn)\u001b[0m\n\u001b[0;32m    593\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[0;32m    594\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 595\u001b[1;33m                                   require_shape_fn)\n\u001b[0m\u001b[0;32m    596\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[1;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[0;32m    657\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 659\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    661\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Dimension 0 in both shapes must be equal, but are 7 and 64 for 'Assign' (op: 'Assign') with input shapes: [7,7,1,64], [64,3,7,7]."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import sys\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import statistics\n",
    "import random\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.models import model_from_json\n",
    "from sklearn.metrics import log_loss\n",
    "from scipy.misc import imread, imresize\n",
    "from sklearn.metrics import log_loss\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Input, Dense, Convolution2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Dropout, Flatten, merge, Reshape, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.layers.core import Layer\n",
    "from keras.engine import InputSpec\n",
    "from keras import initializers as initializations\n",
    "\n",
    "\n",
    "sys.setrecursionlimit(3000)\n",
    "color_type_global = 1\n",
    "\n",
    "def get_im_cv2(path, img_rows, img_cols, color_type=1):\n",
    "    if color_type == 1:           # Load as grayscale\n",
    "        img = cv2.imread(path, 0)\n",
    "    elif color_type == 3:         # Load colored image\n",
    "        img = cv2.imread(path)\n",
    "    # Reduce size\n",
    "    resized = cv2.resize(img, (img_cols, img_rows))\n",
    "    return resized\n",
    "\n",
    "def get_im_cv2_mod(path, img_rows, img_cols, color_type=1):\n",
    "    # Load as grayscale\n",
    "    if color_type == 1:\n",
    "        img = cv2.imread(path, 0)\n",
    "    else:\n",
    "        img = cv2.imread(path)\n",
    "    # Reduce size\n",
    "    rotate = random.uniform(-10, 10)\n",
    "    M = cv2.getRotationMatrix2D((img.shape[1]/2, img.shape[0]/2), rotate, 1)   #randomly generate a rotating matrix\n",
    "    img = cv2.warpAffine(img, M, (img.shape[1], img.shape[0]))                 #rotate img \n",
    "    resized = cv2.resize(img, (img_cols, img_rows), cv2.INTER_LINEAR)\n",
    "    return resized\n",
    "\n",
    "def get_driver_img_list():\n",
    "    dr = dict()\n",
    "    path = os.path.join('..', 'input', 'driver_imgs_list.csv')\n",
    "    print(\"Read drivers' list... ...\")\n",
    "    f = open(path, 'r')\n",
    "    line = f.readline()\n",
    "    while (1):\n",
    "        line = f.readline()\n",
    "        if line == '':\n",
    "            break\n",
    "        arr = line.strip().split(',')\n",
    "        dr[arr[2]] = arr[0]\n",
    "    f.close()\n",
    "    return dr\n",
    "\n",
    "def load_train(img_rows, img_cols, color_type=1):\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    driver_id = []\n",
    "    start_time = time.time()\n",
    "    driver_data = get_driver_img_list()                  #read from driver_imgs_list.csv, files are like p002--c0--img_44733.jpg \n",
    "\n",
    "    print('Read train images... ... ')\n",
    "    for drlabel in range(10):\n",
    "        print('Load folder c{}... ...'.format(drlabel))\n",
    "        path = os.path.join('..', 'input', 'train', 'c' + str(drlabel), '*.jpg')  #path=\"..\\input\\train\\c0\\img_?.jpg\"\n",
    "        files = glob.glob(path)                                                   #collect all *.jpg files' name into files[]\n",
    "        for imgfile in files:\n",
    "            img = get_im_cv2_mod(imgfile,img_rows, img_cols, color_type)\n",
    "            X_train.append(img)\n",
    "            y_train.append(drlabel)                  \n",
    "            filebase = os.path.basename(imgfile)          #filebase is filename excluding the dirpath\n",
    "            driver_id.append(driver_data[filebase])       #assemble driver_id[] from driver_imgs_list.csv\n",
    "\n",
    "    print('Read train data time: {} seconds'.format(round(time.time() - start_time, 2)))\n",
    "    unique_drivers = sorted(list(set(driver_id)))\n",
    "    print('Unique drivers: {}'.format(len(unique_drivers)))\n",
    "    print(unique_drivers)\n",
    "    return X_train, y_train, driver_id, unique_drivers\n",
    "\n",
    "\n",
    "def load_test(img_rows, img_cols, color_type=1):\n",
    "    print('Read test images... ...')\n",
    "    start_time = time.time()\n",
    "    path = os.path.join('..', 'input', 'test', '*.jpg')\n",
    "    files = glob.glob(path)\n",
    "    X_test = []\n",
    "    X_test_id = []\n",
    "    total = 0\n",
    "    thr = math.floor(len(files)/10)               #split test files into 10 batches\n",
    "    for imgfile in files:\n",
    "        img = get_im_cv2_mod(imgfile, img_rows, img_cols, color_type)\n",
    "        X_test.append(img)\n",
    "        filebase = os.path.basename(imgfile)\n",
    "        X_test_id.append(filebase)\n",
    "        total += 1\n",
    "        if total%thr == 0:                        #each time start a new batch, print out a message\n",
    "            print('Read {} images from {}'.format(total, len(files)))\n",
    "    \n",
    "    print('Read test data time: {} seconds'.format(round(time.time() - start_time, 2)))\n",
    "    return X_test, X_test_id\n",
    "\n",
    "\n",
    "def cache_data(data, path):\n",
    "    if os.path.isdir(os.path.dirname(path)):\n",
    "        file = open(path, 'wb')\n",
    "        pickle.dump(data, file)\n",
    "        file.close()\n",
    "    else:\n",
    "        print('Directory doesnt exists')\n",
    "\n",
    "\n",
    "def restore_data(path):\n",
    "    data = dict()\n",
    "    if os.path.isfile(path):\n",
    "        file = open(path, 'rb')\n",
    "        data = pickle.load(file)\n",
    "    return data\n",
    "\n",
    "\n",
    "def save_model(model):\n",
    "    json_string = model.to_json()\n",
    "    if not os.path.isdir('cache'):\n",
    "        os.mkdir('cache')\n",
    "    open(os.path.join('cache', 'architecture.json'), 'w').write(json_string)\n",
    "    model.save_weights(os.path.join('cache', 'model_weights.h5'), overwrite=True)\n",
    "\n",
    "\n",
    "def read_model():\n",
    "    model = model_from_json(open(os.path.join('cache', 'architecture.json')).read())\n",
    "    model.load_weights(os.path.join('cache', 'model_weights.h5'))\n",
    "    return model\n",
    "\n",
    "\n",
    "def split_validation_set(train, target, test_size):\n",
    "    random_state = 51\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train, target, test_size=test_size, random_state=random_state)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def create_submission(predictions, test_id, info):\n",
    "    result1 = pd.DataFrame(predictions, columns=['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9'])\n",
    "    result1.loc[:, 'img'] = pd.Series(test_id, index=result1.index)\n",
    "    now = datetime.datetime.now()\n",
    "    if not os.path.isdir('subm'):\n",
    "        os.mkdir('subm')\n",
    "    suffix = info + '_' + str(now.strftime(\"%Y-%m-%d-%H-%M\"))\n",
    "    sub_file = os.path.join('subm', 'submission_' + suffix + '.csv')\n",
    "    result1.to_csv(sub_file, index=False)\n",
    "\n",
    "\n",
    "def read_and_normalize_train_data(img_rows, img_cols, color_type=1):\n",
    "    cache_path = os.path.join('cache', 'train_r_' + str(img_rows) + '_c_' + str(img_cols) + '_t_' + str(color_type) + '.dat')\n",
    "    if not os.path.isfile(cache_path) or use_cache == 0:\n",
    "        train_data, train_target, driver_id, unique_drivers = load_train(img_rows, img_cols, color_type)\n",
    "        cache_data((train_data, train_target, driver_id, unique_drivers), cache_path)\n",
    "    else:\n",
    "        print('Restore train from cache!')\n",
    "        (train_data, train_target, driver_id, unique_drivers) = restore_data(cache_path)\n",
    "\n",
    "    train_data = np.array(train_data, dtype=np.uint8)\n",
    "    train_target = np.array(train_target, dtype=np.uint8)\n",
    "    train_data = train_data.reshape(train_data.shape[0], color_type, img_rows, img_cols)\n",
    "    train_target = np_utils.to_categorical(train_target, 10)\n",
    "    train_data = train_data.astype('float32')\n",
    "    train_data /= 255\n",
    "    print('Train shape:', train_data.shape)\n",
    "    print(train_data.shape[0], 'train samples')\n",
    "    return train_data, train_target, driver_id, unique_drivers\n",
    "\n",
    "\n",
    "def read_and_normalize_test_data(img_rows, img_cols, color_type=1):\n",
    "    cache_path = os.path.join('cache', 'test_r_' + str(img_rows) + '_c_' + str(img_cols) + '_t_' + str(color_type) + '.dat')\n",
    "    if not os.path.isfile(cache_path) or use_cache == 0:\n",
    "        test_data, test_id = load_test(img_rows, img_cols, color_type)\n",
    "        cache_data((test_data, test_id), cache_path)\n",
    "    else:\n",
    "        print('Restore test from cache!')\n",
    "        (test_data, test_id) = restore_data(cache_path)\n",
    "\n",
    "    test_data = np.array(test_data, dtype=np.uint8)\n",
    "    test_data = test_data.reshape(test_data.shape[0], color_type, img_rows, img_cols)\n",
    "    test_data = test_data.astype('float32')\n",
    "    test_data /= 255\n",
    "    print('Test shape:', test_data.shape)\n",
    "    print(test_data.shape[0], 'test samples')\n",
    "    return test_data, test_id\n",
    "\n",
    "\n",
    "def dict_to_list(d):\n",
    "    ret = []\n",
    "    for i in d.items():\n",
    "        ret.append(i[1])\n",
    "    return ret\n",
    "\n",
    "\n",
    "def merge_several_folds_mean(data, nfolds):\n",
    "    a = np.array(data[0])\n",
    "    for i in range(1, nfolds):\n",
    "        a += np.array(data[i])\n",
    "    a /= nfolds\n",
    "    return a.tolist()\n",
    "\n",
    "\n",
    "def merge_several_folds_geom(data, nfolds):\n",
    "    a = np.array(data[0])\n",
    "    for i in range(1, nfolds):\n",
    "        a *= np.array(data[i])\n",
    "    a = np.power(a, 1/nfolds)\n",
    "    return a.tolist()\n",
    "\n",
    "\n",
    "def copy_selected_drivers(train_data, train_target, driver_id, driver_list):\n",
    "    data = []\n",
    "    target = []\n",
    "    index = []\n",
    "    for i in range(len(driver_id)):\n",
    "        if driver_id[i] in driver_list:\n",
    "            data.append(train_data[i])\n",
    "            target.append(train_target[i])\n",
    "            index.append(i)\n",
    "    data = np.array(data, dtype=np.float32)\n",
    "    target = np.array(target, dtype=np.float32)\n",
    "    index = np.array(index, dtype=np.uint32)\n",
    "    return data, target, index\n",
    "\n",
    "##------------------------------------------------------------------------------------\n",
    "\n",
    "class Scale(Layer):\n",
    "    '''Learns a set of weights and biases used for scaling the input data.\n",
    "    the output consists simply in an element-wise multiplication of the input\n",
    "    and a sum of a set of constants:\n",
    "        out = in * gamma + beta,\n",
    "    where 'gamma' and 'beta' are the weights and biases larned.\n",
    "    # Arguments\n",
    "        axis: integer, axis along which to normalize in mode 0. For instance,\n",
    "            if your input tensor has shape (samples, channels, rows, cols),\n",
    "            set axis to 1 to normalize per feature map (channels axis).\n",
    "        momentum: momentum in the computation of the\n",
    "            exponential average of the mean and standard deviation\n",
    "            of the data, for feature-wise normalization.\n",
    "        weights: Initialization weights.\n",
    "            List of 2 Numpy arrays, with shapes:\n",
    "            `[(input_shape,), (input_shape,)]`\n",
    "        beta_init: name of initialization function for shift parameter\n",
    "            (see [initializations](../initializations.md)), or alternatively,\n",
    "            Theano/TensorFlow function to use for weights initialization.\n",
    "            This parameter is only relevant if you don't pass a `weights` argument.\n",
    "        gamma_init: name of initialization function for scale parameter (see\n",
    "            [initializations](../initializations.md)), or alternatively,\n",
    "            Theano/TensorFlow function to use for weights initialization.\n",
    "            This parameter is only relevant if you don't pass a `weights` argument.\n",
    "    '''\n",
    "    def __init__(self, weights=None, axis=-1, momentum = 0.9, beta_init='zero', gamma_init='one', **kwargs):\n",
    "        self.momentum = momentum\n",
    "        self.axis = axis\n",
    "        self.beta_init = initializations.get(beta_init)\n",
    "        self.gamma_init = initializations.get(gamma_init)\n",
    "        self.initial_weights = weights\n",
    "        super(Scale, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.input_spec = [InputSpec(shape=input_shape)]\n",
    "        shape = (int(input_shape[self.axis]),)\n",
    "\n",
    "        # Compatibility with TensorFlow >= 1.0.0\n",
    "        self.gamma = K.variable(self.gamma_init(shape), name='{}_gamma'.format(self.name))\n",
    "        self.beta = K.variable(self.beta_init(shape), name='{}_beta'.format(self.name))\n",
    "        #self.gamma = self.gamma_init(shape, name='{}_gamma'.format(self.name))\n",
    "        #self.beta = self.beta_init(shape, name='{}_beta'.format(self.name))\n",
    "        self.trainable_weights = [self.gamma, self.beta]\n",
    "\n",
    "        if self.initial_weights is not None:\n",
    "            self.set_weights(self.initial_weights)\n",
    "            del self.initial_weights\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        input_shape = self.input_spec[0].shape\n",
    "        broadcast_shape = [1] * len(input_shape)\n",
    "        broadcast_shape[self.axis] = input_shape[self.axis]\n",
    "\n",
    "        out = K.reshape(self.gamma, broadcast_shape) * x + K.reshape(self.beta, broadcast_shape)\n",
    "        return out\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\"momentum\": self.momentum, \"axis\": self.axis}\n",
    "        base_config = super(Scale, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "    \n",
    "\n",
    "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
    "    '''The identity_block is the block that has no conv layer at shortcut\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: defualt 3, the kernel size of middle conv layer at main path\n",
    "        filters: list of integers, the nb_filters of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "    '''\n",
    "    eps = 1.1e-5\n",
    "    nb_filter1, nb_filter2, nb_filter3 = filters\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    scale_name_base = 'scale' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = Convolution2D(nb_filter1, 1, 1, name=conv_name_base + '2a', bias=False)(input_tensor)\n",
    "    x = BatchNormalization(epsilon=eps, axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Scale(axis=bn_axis, name=scale_name_base + '2a')(x)\n",
    "    x = Activation('relu', name=conv_name_base + '2a_relu')(x)\n",
    "\n",
    "    x = ZeroPadding2D((1, 1), name=conv_name_base + '2b_zeropadding')(x)\n",
    "    x = Convolution2D(nb_filter2, kernel_size, kernel_size,\n",
    "                      name=conv_name_base + '2b', bias=False)(x)\n",
    "    x = BatchNormalization(epsilon=eps, axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Scale(axis=bn_axis, name=scale_name_base + '2b')(x)\n",
    "    x = Activation('relu', name=conv_name_base + '2b_relu')(x)\n",
    "\n",
    "    x = Convolution2D(nb_filter3, 1, 1, name=conv_name_base + '2c', bias=False)(x)\n",
    "    x = BatchNormalization(epsilon=eps, axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "    x = Scale(axis=bn_axis, name=scale_name_base + '2c')(x)\n",
    "\n",
    "    x = merge([x, input_tensor], mode='sum', name='res' + str(stage) + block)\n",
    "    x = Activation('relu', name='res' + str(stage) + block + '_relu')(x)\n",
    "    return x\n",
    "\n",
    "def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n",
    "    '''conv_block is the block that has a conv layer at shortcut\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: defualt 3, the kernel size of middle conv layer at main path\n",
    "        filters: list of integers, the nb_filters of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "    Note that from stage 3, the first conv layer at main path is with subsample=(2,2)\n",
    "    And the shortcut should have subsample=(2,2) as well\n",
    "    '''\n",
    "    eps = 1.1e-5\n",
    "    nb_filter1, nb_filter2, nb_filter3 = filters\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    scale_name_base = 'scale' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = Convolution2D(nb_filter1, 1, 1, subsample=strides,\n",
    "                      name=conv_name_base + '2a', bias=False)(input_tensor)\n",
    "    x = BatchNormalization(epsilon=eps, axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Scale(axis=bn_axis, name=scale_name_base + '2a')(x)\n",
    "    x = Activation('relu', name=conv_name_base + '2a_relu')(x)\n",
    "\n",
    "    x = ZeroPadding2D((1, 1), name=conv_name_base + '2b_zeropadding')(x)\n",
    "    x = Convolution2D(nb_filter2, kernel_size, kernel_size,\n",
    "                      name=conv_name_base + '2b', bias=False)(x)\n",
    "    x = BatchNormalization(epsilon=eps, axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Scale(axis=bn_axis, name=scale_name_base + '2b')(x)\n",
    "    x = Activation('relu', name=conv_name_base + '2b_relu')(x)\n",
    "\n",
    "    x = Convolution2D(nb_filter3, 1, 1, name=conv_name_base + '2c', bias=False)(x)\n",
    "    x = BatchNormalization(epsilon=eps, axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "    x = Scale(axis=bn_axis, name=scale_name_base + '2c')(x)\n",
    "\n",
    "    shortcut = Convolution2D(nb_filter3, 1, 1, subsample=strides,\n",
    "                             name=conv_name_base + '1', bias=False)(input_tensor)\n",
    "    shortcut = BatchNormalization(epsilon=eps, axis=bn_axis, name=bn_name_base + '1')(shortcut)\n",
    "    shortcut = Scale(axis=bn_axis, name=scale_name_base + '1')(shortcut)\n",
    "\n",
    "    x = merge([x, shortcut], mode='sum', name='res' + str(stage) + block)\n",
    "    x = Activation('relu', name='res' + str(stage) + block + '_relu')(x)\n",
    "    return x\n",
    "\n",
    "def resnet101_model(img_rows, img_cols, color_type=1, num_classes=None):\n",
    "    \"\"\"\n",
    "    Resnet 101 Model for Keras\n",
    "    Model Schema and layer naming follow that of the original Caffe implementation\n",
    "    https://github.com/KaimingHe/deep-residual-networks\n",
    "    ImageNet Pretrained Weights \n",
    "    Theano: https://drive.google.com/file/d/0Byy2AcGyEVxfdUV1MHJhelpnSG8/view?usp=sharing\n",
    "    TensorFlow: https://drive.google.com/file/d/0Byy2AcGyEVxfTmRRVmpGWDczaXM/view?usp=sharing\n",
    "    Parameters:\n",
    "      img_rows, img_cols - resolution of inputs\n",
    "      channel - 1 for grayscale, 3 for color \n",
    "      num_classes - number of class labels for our classification task\n",
    "    \"\"\"\n",
    "    eps = 1.1e-5\n",
    "\n",
    "    # Handle Dimension Ordering for different backends\n",
    "    \"\"\"\n",
    "    global bn_axis\n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "      bn_axis = 3\n",
    "      img_input = Input(shape=(img_rows, img_cols, color_type), name='data')\n",
    "    else:\n",
    "      bn_axis = 1\n",
    "      img_input = Input(shape=(color_type, img_rows, img_cols), name='data')\n",
    "    \"\"\"    \n",
    "        \n",
    "    img_input = Input(shape=(img_rows, img_cols, color_type), name='data')\n",
    "    global bn_axis\n",
    "    bn_axis=3\n",
    "\n",
    "    x = ZeroPadding2D((3, 3), name='conv1_zeropadding')(img_input)\n",
    "    x = Convolution2D(64, 7, 7, subsample=(2, 2), name='conv1', bias=False)(x)\n",
    "    x = BatchNormalization(epsilon=eps, axis=bn_axis, name='bn_conv1')(x)\n",
    "    x = Scale(axis=bn_axis, name='scale_conv1')(x)\n",
    "    x = Activation('relu', name='conv1_relu')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), name='pool1')(x)\n",
    "\n",
    "    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n",
    "    for i in range(1,4):\n",
    "      x = identity_block(x, 3, [128, 128, 512], stage=3, block='b'+str(i))\n",
    "\n",
    "    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n",
    "    for i in range(1,23):\n",
    "      x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b'+str(i))\n",
    "\n",
    "    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "    x_fc = AveragePooling2D((7, 7), name='avg_pool')(x)\n",
    "    x_fc = Flatten()(x_fc)\n",
    "    x_fc = Dense(1000, activation='softmax', name='fc1000')(x_fc)\n",
    "\n",
    "    model = Model(img_input, x_fc)\n",
    "\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "      # Use pre-trained weights for Theano backend\n",
    "      weights_path = 'imagenet_models/resnet101_weights_th.h5'\n",
    "    else:\n",
    "      # Use pre-trained weights for Tensorflow backend\n",
    "      weights_path = 'imagenet_models/resnet101_weights_tf.h5'\n",
    "\n",
    "    model.load_weights(weights_path, by_name=True)\n",
    "\n",
    "    # Truncate and replace softmax layer for transfer learning\n",
    "    # Cannot use model.layers.pop() since model is not of Sequential() type\n",
    "    # The method below works since pre-trained weights are stored in layers but not in the model\n",
    "    x_newfc = AveragePooling2D((7, 7), name='avg_pool')(x)\n",
    "    x_newfc = Flatten()(x_newfc)\n",
    "    x_newfc = Dense(num_classes, activation='softmax', name='fc8')(x_newfc)\n",
    "\n",
    "    model = Model(img_input, x_newfc)\n",
    "\n",
    "    # Learning rate is changed to 0.001\n",
    "    sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\"\"\"\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Example to fine-tune on 3000 samples from Cifar10\n",
    "\n",
    "    img_rows, img_cols = 224, 224 # Resolution of inputs\n",
    "    channel = 3\n",
    "    num_classes = 10 \n",
    "    batch_size = 16 \n",
    "    nb_epoch = 10\n",
    "\n",
    "    # Load Cifar10 data. Please implement your own load_data() module for your own dataset\n",
    "    X_train, Y_train, X_valid, Y_valid = load_train(img_rows, img_cols,color_type=1)\n",
    "\n",
    "    # Load our model\n",
    "    model = resnet101_model(img_rows, img_cols, channel, num_classes)\n",
    "\n",
    "    # Start Fine-tuning\n",
    "    model.fit(X_train, Y_train,\n",
    "              batch_size=batch_size,\n",
    "              nb_epoch=nb_epoch,\n",
    "              shuffle=True,\n",
    "              verbose=1,\n",
    "              validation_data=(X_valid, Y_valid),\n",
    "              )\n",
    "\n",
    "    # Make predictions\n",
    "    predictions_valid = model.predict(X_valid, batch_size=batch_size, verbose=1)\n",
    "\n",
    "    # Cross-entropy loss score\n",
    "    score = log_loss(Y_valid, predictions_valid)\n",
    " \n",
    "\"\"\"\n",
    "##------------------------------------------------------------------------------------\n",
    "    \n",
    "def run_single():\n",
    "    # input image dimensions\n",
    "    img_rows, img_cols = 224, 224\n",
    "    batch_size = 32\n",
    "    nb_epoch = 1\n",
    "    random_state = 51\n",
    "\n",
    "    train_data, train_target, driver_id, unique_drivers = read_and_normalize_train_data(img_rows, img_cols, color_type_global)\n",
    "    test_data, test_id = read_and_normalize_test_data(img_rows, img_cols, color_type_global)\n",
    "\n",
    "    yfull_train = dict()\n",
    "    yfull_test = []\n",
    "    unique_list_train = ['p002', 'p012', 'p014', 'p015', 'p016', 'p021', 'p022', 'p024',\n",
    "                     'p026', 'p035', 'p039', 'p041', 'p042', 'p045', 'p047', 'p049',\n",
    "                     'p050', 'p051', 'p052', 'p056', 'p061', 'p064', 'p066', 'p072',\n",
    "                     'p075']\n",
    "    X_train, Y_train, train_index = copy_selected_drivers(train_data, train_target, driver_id, unique_list_train)\n",
    "    unique_list_valid = ['p081']\n",
    "    X_valid, Y_valid, test_index = copy_selected_drivers(train_data, train_target, driver_id, unique_list_valid)\n",
    "\n",
    "    print('Start Single Run')\n",
    "    print('Split train: ', len(X_train), len(Y_train))\n",
    "    print('Split valid: ', len(X_valid), len(Y_valid))\n",
    "    print('Train drivers: ', unique_list_train)\n",
    "    print('Test drivers: ', unique_list_valid)\n",
    "\n",
    "#    model = create_model_v1(img_rows, img_cols, color_type_global)\n",
    "    model =  resnet101_model(img_rows, img_cols, color_type_global)\n",
    "    model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "               shuffle=True, verbose=1, validation_data=(X_valid, Y_valid))\n",
    "\n",
    "    # score = model.evaluate(X_valid, Y_valid, show_accuracy=True, verbose=0)\n",
    "    # print('Score log_loss: ', score[0])\n",
    "\n",
    "    predictions_valid = model.predict(X_valid, batch_size=128, verbose=1)\n",
    "    score = log_loss(Y_valid, predictions_valid)\n",
    "    print('Score log_loss: ', score)\n",
    "\n",
    "    # Store valid predictions\n",
    "    for i in range(len(test_index)):\n",
    "        yfull_train[test_index[i]] = predictions_valid[i]\n",
    "\n",
    "    # Store test predictions\n",
    "    test_prediction = model.predict(test_data, batch_size=128, verbose=1)\n",
    "    yfull_test.append(test_prediction)\n",
    "\n",
    "    print('Final log_loss: {}, rows: {} cols: {} epoch: {}'.format(score, img_rows, img_cols, nb_epoch))\n",
    "    info_string = 'loss_' + str(score) \\\n",
    "                    + '_r_' + str(img_rows) \\\n",
    "                    + '_c_' + str(img_cols) \\\n",
    "                    + '_ep_' + str(nb_epoch)\n",
    "\n",
    "    test_res = merge_several_folds_mean(yfull_test, 1)\n",
    "    create_submission(test_res, test_id, info_string)\n",
    "\n",
    "\n",
    "run_single()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
